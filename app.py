# app.py
import os
import re
import time
import glob
import shutil
from pathlib import Path
from typing import List, Dict, Optional

import streamlit as st
import pandas as pd

import yt_dlp
import whisper
from detoxify import Detoxify

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM  # Zephyr

# -------------------------
# Config
# -------------------------
WHISPER_MODEL_SIZE = "base"
TOXICITY_THRESHOLD = 0.10
REPHRASE_MODEL_NAME = "HuggingFaceH4/zephyr-7b-beta"  # open; no token required
MAX_NEW_TOKENS = 96
NUM_BEAMS = 4

DOWNLOAD_DIR = Path("downloads")
UPLOAD_DIR   = Path("uploaded_audio")
OUTPUTS_DIR  = Path("outputs")
for d in (DOWNLOAD_DIR, UPLOAD_DIR, OUTPUTS_DIR):
    d.mkdir(exist_ok=True)

st.set_page_config(page_title="YouTube/Audio Detoxifier", layout="wide")
st.title("ðŸŽµ YouTube / Local Audio â†’ Whisper â†’ Detoxify â†’ Zephyr Rephrase")

# -------------------------
# FFmpeg discovery (so yt_dlp/whisper work on Windows)
# -------------------------
def _find_ffmpeg_bin() -> Optional[Path]:
    # 1) PATH
    got = shutil.which("ffmpeg")
    if got:
        return Path(got).parent
    # 2) Common Windows locations
    candidates = [
        Path(r"C:\Users\HP\Downloads\ffmpeg-8.0-essentials_build\ffmpeg-8.0-essentials_build\bin"),
        Path(r"C:\Users\HP\Downloads\ffmpeg-8.0-essentials_build\ffmpeg-8.0-essentials_build\bin"),
        Path.home() / "scoop" / "apps" / "ffmpeg" / "current" / "bin",
        Path.home() / "Downloads" / "ffmpeg-8.0-essentials_build" / "bin",
    ]
    for c in candidates:
        if (c / "ffmpeg.exe").exists():
            return c
    return None

FFMPEG_BIN = _find_ffmpeg_bin()
if FFMPEG_BIN:
    os.environ["PATH"] = str(FFMPEG_BIN) + os.pathsep + os.environ.get("PATH", "")
else:
    st.warning("FFmpeg not found. Install it (e.g., `winget install Gyan.FFmpeg`) or add its `bin` to PATH.")

# -------------------------
# Utilities from your code
# -------------------------
def sanitize_title(title: str) -> str:
    safe_title = "".join(c for c in title if c.isalnum() or c in (" ", "-", "_")).strip()
    safe_title = safe_title.replace(" ", "_")
    return safe_title[:100] if safe_title else "audio"

def split_into_sentences(text: str) -> List[str]:
    raw = [s.strip() for s in re.split(r'(?<=[.!?])\s+', text.strip()) if s.strip()]
    return [s for s in raw if len(s.split()) >= 3]

# -------------------------
# Downloads / Transcription
# -------------------------
def download_youtube_audio(url: str) -> Optional[str]:
    if not url:
        return None

    # clean stale temps
    for f in DOWNLOAD_DIR.glob("temp_audio*"):
        try:
            f.unlink()
        except Exception:
            pass

    temp_base = DOWNLOAD_DIR / "temp_audio"
    ydl_opts = {
        "format": "bestaudio/best",
        "outtmpl": str(temp_base),
        "quiet": True,
        "postprocessors": [{
            "key": "FFmpegExtractAudio",
            "preferredcodec": "wav",
            "preferredquality": "192",
        }],
        "noprogress": True,
        "logtostderr": False,
        # if ffmpeg found, hint yt_dlp
        **({"ffmpeg_location": str(FFMPEG_BIN)} if FFMPEG_BIN else {}),
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)
            title = info.get("title", "unknown_video")
            final_name = DOWNLOAD_DIR / f"{sanitize_title(title)}.wav"

            processed_file = Path(str(temp_base) + ".wav")
            if processed_file.exists():
                if final_name.exists() and processed_file != final_name:
                    final_name.unlink()
                processed_file.rename(final_name)
                time.sleep(0.3)
                return str(final_name)

            wav_files = glob.glob(str(DOWNLOAD_DIR / "temp_audio") + "*.wav")
            if wav_files:
                Path(wav_files[0]).rename(final_name)
                time.sleep(0.3)
                return str(final_name)

            st.error("Audio file not generated by yt-dlp postprocessor.")
            return None
    except Exception as e:
        st.error(f"Download error: {e}")
        return None

@st.cache_resource
def load_whisper_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = whisper.load_model(WHISPER_MODEL_SIZE, device=device)
    return model, device

def transcribe_with_whisper(audio_path: str) -> Optional[str]:
    p = Path(audio_path)
    if not p.exists():
        st.error(f"File not found: {p}")
        return None
    model, device = load_whisper_model()
    try:
        # avoid FP16 warning on CPU
        kw = {} if device == "cuda" else {"fp16": False}
        result = model.transcribe(str(p), **kw)
        return (result.get("text") or "").strip()
    except Exception as e:
        st.error(f"Transcription error: {e}")
        return None

# -------------------------
# Detoxify + Zephyr
# -------------------------
@st.cache_resource
def load_detoxify():
    return Detoxify("original")

def _looks_same(a: str, b: str) -> bool:
    if not a or not b:
        return a == b
    norm = lambda x: re.sub(r'\s+', ' ', re.sub(r'[^\w\s]', '', x.lower())).strip()
    return norm(a) == norm(b)

def _zephyr_prompt(sentence: str) -> str:
    return (
        "Rewrite the following sentence to be polite, neutral, and constructive, "
        "while preserving the original meaning. Do not repeat it verbatim. "
        "Output only the rewritten sentence.\n\n"
        f"Sentence: {sentence}\nRewritten:"
    )

def _pick_dtype():
    return torch.float16 if torch.cuda.is_available() else torch.float32

@st.cache_resource
def load_rephrase_model(model_name: str):
    dtype = _pick_dtype()
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        device_map="auto",
        torch_dtype=dtype,
    )
    device = next(model.parameters()).device
    return tokenizer, model, device

def rephrase_sentence(sentence: str, tokenizer, model, device) -> str:
    s = sentence.strip()
    if not s:
        return ""
    prompt = _zephyr_prompt(s)
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512).to(device)

    with torch.no_grad():
        out = model.generate(
            **inputs,
            max_new_tokens=MAX_NEW_TOKENS,
            num_beams=NUM_BEAMS,
            early_stopping=True,
            no_repeat_ngram_size=3,
            repetition_penalty=1.1,
            length_penalty=1.05,
        )
    text = tokenizer.decode(out[0], skip_special_tokens=True).strip()
    if text and not _looks_same(text, s):
        return text

    with torch.no_grad():
        out = model.generate(
            **inputs,
            max_new_tokens=MAX_NEW_TOKENS,
            do_sample=True,
            top_p=0.9,
            temperature=0.9,
            top_k=50,
            no_repeat_ngram_size=3,
            repetition_penalty=1.2,
        )
    text2 = tokenizer.decode(out[0], skip_special_tokens=True).strip()
    return text2 if text2 and not _looks_same(text2, s) else "[review: model echoed input]"

def analyze_text(text: str,
                 threshold: float = TOXICITY_THRESHOLD) -> List[Dict[str, str]]:
    sentences = split_into_sentences(text)
    results = []

    detox = load_detoxify()
    tokenizer, model, device = load_rephrase_model(REPHRASE_MODEL_NAME)

    progress = st.progress(0)
    n = max(1, len(sentences))
    for i, s in enumerate(sentences):
        try:
            scores = detox.predict(s) or {}
        except Exception:
            scores = {}
        max_score = 0.0
        toxic = False
        for _, v in scores.items():
            try:
                fv = float(v)
            except Exception:
                fv = 0.0
            max_score = max(max_score, fv)
            if fv > threshold:
                toxic = True

        if toxic:
            try:
                rephrased = rephrase_sentence(s, tokenizer, model, device)
            except Exception as e:
                rephrased = f"[Rephrasing failed: {e}]"

            results.append({
                "Toxic Phrase": s,
                "Polite Rephrase": rephrased,
                "Toxicity Score (Max)": f"{max_score:.4f}",
            })

        progress.progress(int(((i + 1) / n) * 100))
    progress.empty()
    return results

# -------------------------
# UI Layout
# -------------------------
st.markdown("Choose a source, then click **Analyze**.")

tab_url, tab_upload = st.tabs(["YouTube URL", "Local Audio File"])

with tab_url:
    url = st.text_input("YouTube URL")
    if st.button("Extract & Analyze from YouTube", type="primary", use_container_width=True):
        with st.spinner("Step 1/3: Downloading audioâ€¦"):
            audio_path = download_youtube_audio(url)
        if audio_path:
            with st.spinner("Step 2/3: Transcribing with Whisperâ€¦"):
                text = transcribe_with_whisper(audio_path)
            if text:
                with st.spinner("Step 3/3: Analyzing & rephrasing toxic sentencesâ€¦"):
                    results = analyze_text(text)
                if results:
                    df = pd.DataFrame(results)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                    out_csv = OUTPUTS_DIR / "detoxification_results.csv"
                    df.to_csv(out_csv, index=False, encoding="utf-8")
                    st.download_button("Download CSV", data=out_csv.read_bytes(),
                                       file_name="detoxification_results.csv", mime="text/csv")
                else:
                    st.success("âœ… No sentences exceeded the toxicity threshold.")

with tab_upload:
    uploaded = st.file_uploader("Upload audio (MP3, WAV, M4A, FLAC, OGG, WEBM)",
                                type=["mp3", "wav", "m4a", "flac", "ogg", "webm"])
    if st.button("Analyze Uploaded Audio", use_container_width=True):
        if not uploaded:
            st.warning("Please upload a file first.")
        else:
            with st.spinner("Preparing fileâ€¦"):
                dst = UPLOAD_DIR / uploaded.name
                with open(dst, "wb") as f:
                    f.write(uploaded.getbuffer())
            with st.spinner("Step 2/3: Transcribing with Whisperâ€¦"):
                text = transcribe_with_whisper(str(dst))
            if text:
                with st.spinner("Step 3/3: Analyzing & rephrasing toxic sentencesâ€¦"):
                    results = analyze_text(text)
                if results:
                    df = pd.DataFrame(results)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                    out_csv = OUTPUTS_DIR / "detoxification_results.csv"
                    df.to_csv(out_csv, index=False, encoding="utf-8")
                    st.download_button("Download CSV", data=out_csv.read_bytes(),
                                       file_name="detoxification_results.csv", mime="text/csv")
                else:
                    st.success("âœ… No sentences exceeded the toxicity threshold.")
